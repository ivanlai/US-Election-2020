{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code copied and modified from: \\\n",
    "https://github.com/gabrielpreda/covid-19-tweets/blob/master/covid-19-tweets.ipynb\n",
    "\n",
    "\n",
    "Twitter API reference : \\\n",
    "https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/overview/tweet-object \\\n",
    "https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/overview/user-object\n",
    "\n",
    "\n",
    "Tweepy reference: \\\n",
    "http://docs.tweepy.org/en/latest/api.html \\\n",
    "http://docs.tweepy.org/en/latest/auth_tutorial.html\n",
    "\n",
    "\n",
    "Tips: \\\n",
    "https://bhaskarvk.github.io/2015/01/how-to-use-twitters-search-rest-api-most-effectively./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import tweepy as tw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from datetime import date, datetime\n",
    "from IPython.display import clear_output\n",
    "\n",
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = \"#Trump OR #Biden -filter:retweets\"\n",
    "fname        = \"Tweets_US.csv\"\n",
    "inputFolder  = 'input'\n",
    "\n",
    "date_until   = date.today().strftime(\"%Y-%m-%d\")\n",
    "tweetsPerQry = 100\n",
    "\n",
    "DEBUG        = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.join(inputFolder, fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Twitter API authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWITTER_CONSUMER_API_KEY    = os.environ[\"TWITTER_CONSUMER_API_KEY\"]\n",
    "TWITTER_CONSUMER_API_SECRET = os.environ[\"TWITTER_CONSUMER_API_SECRET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API authenticated and ready.\n"
     ]
    }
   ],
   "source": [
    "# auth = tw.OAuthHandler(TWITTER_CONSUMER_API_KEY, TWITTER_CONSUMER_API_SECRET)\n",
    "\n",
    "auth = tw.AppAuthHandler(TWITTER_CONSUMER_API_KEY, TWITTER_CONSUMER_API_SECRET) #This is faster with a higher rate limit\n",
    "api  = tw.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "if (not api):\n",
    "    print (\"Can't Authenticate\")\n",
    "else:\n",
    "    print(\"API authenticated and ready.\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Read Past Data (to get since_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past tweets: (621404, 20)\n",
      "621,404 tweets archived at 2020-11-02 08:39:58.473429\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(fname):\n",
    "    toConcate     = True\n",
    "    tweets_old_df = pd.read_csv(fname, lineterminator='\\n')\n",
    "    since_id      = tweets_old_df.id.values[0]\n",
    "    print(f\"past tweets: {tweets_old_df.shape}\")\n",
    "    \n",
    "    # Archive old tweets -------------------------#\n",
    "    today = date.today().strftime(\"%Y_%m_%d\")\n",
    "    tweets_old_df.to_csv(f\"{fname.replace('.csv', '')}_{today}.csv\", index=False)\n",
    "    print(f\"{len(tweets_old_df) :,} tweets archived at {str(datetime.now())}\")\n",
    "    \n",
    "else:\n",
    "    toConcate = False\n",
    "    since_id  = None\n",
    "    print(f\"No old tweets\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Get Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettyPrintStatus(status):\n",
    "    json_str = json.dumps(status._json)\n",
    "\n",
    "    #deserialise string into python object\n",
    "    parsed = json.loads(json_str)\n",
    "\n",
    "    print(json.dumps(parsed, indent=4, sort_keys=True))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_tweets_df(tweets):    \n",
    "    rows = []\n",
    "    for tweet in tweets:  \n",
    "        \n",
    "        if 'media' in tweet.entities.keys():\n",
    "            media_type =  [media[\"type\"] for media in tweet.entities[\"media\"]]\n",
    "        else:\n",
    "            media_type = None            \n",
    "\n",
    "        if 'extended_entities' in json.loads(json.dumps(tweet._json)):\n",
    "            extended_media_type =  np.unique([media[\"type\"] for media in tweet.extended_entities[\"media\"]])\n",
    "        else:\n",
    "            extended_media_type = None\n",
    "\n",
    "        row = {'id'                    : tweet.id,\n",
    "               'user_name'             : tweet.user.name, \n",
    "               'user_location'         : tweet.user.location,\n",
    "               'user_description'      : tweet.user.description,\n",
    "               'user_created'          : tweet.user.created_at,\n",
    "               'user_followers'        : tweet.user.followers_count,\n",
    "               'user_friends'          : tweet.user.friends_count,\n",
    "               'user_favourites'       : tweet.user.favourites_count,\n",
    "               'user_verified'         : tweet.user.verified,\n",
    "               'coordinates'           : tweet.coordinates,\n",
    "               'timestamp'             : tweet.created_at,\n",
    "               'text'                  : tweet.full_text, \n",
    "               'truncated'             : tweet.truncated, \n",
    "               'hashtags'              : [hashtag[\"text\"] for hashtag in tweet.entities[\"hashtags\"]],\n",
    "               'retweet_count'         : tweet.retweet_count,\n",
    "               'favorite_count'        : tweet.favorite_count, #likes count\n",
    "               'has_media_type'        : extended_media_type,            \n",
    "               'in_reply_to_status_id' : tweet.in_reply_to_status_id,\n",
    "               'source'                : tweet.source,\n",
    "               'is_retweet'            : tweet.retweeted,        \n",
    "             }    \n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new tweets retrieved: 0\n",
      "Total tweets collected: 23,850\n",
      "CPU times: user 46.9 s, sys: 1.83 s, total: 48.7 s\n",
      "Wall time: 1h 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_tweets = pd.DataFrame()\n",
    "\n",
    "max_id = None\n",
    "count  = 0\n",
    "\n",
    "while True:    \n",
    "    # Collect new tweets (further back in time)--------#\n",
    "    tweets = tw.Cursor(api.search,\n",
    "                       q          = search_words,                    \n",
    "                       tweet_mode = \"extended\", # needed to get full_text                   \n",
    "                       lang       = \"en\",\n",
    "                       since_id   = str(since_id - 1) if since_id else None, #lower bound\n",
    "                       max_id     = str(max_id - 1) if max_id else None,     #upper bound\n",
    "                       until      = date_until\n",
    "                      ).items(tweetsPerQry)\n",
    "    \n",
    "    tweets_copy = []\n",
    "    for tweet in tweets:\n",
    "        tweets_copy.append(tweet)\n",
    "\n",
    "    print(f\"new tweets retrieved: {len(tweets_copy)}\")\n",
    "    #--------------------------------------------------#    \n",
    "    \n",
    "    #Break if no more tweets returned -----------------#\n",
    "    if len(tweets_copy) == 0:\n",
    "        break\n",
    "        \n",
    "        \n",
    "    #Convert to Dataframe -----------------------------#\n",
    "    new_tweets = get_tweets_df(tweets_copy)    \n",
    "    \n",
    "    \n",
    "    #Concat new tweets with existing ones -------------#                    \n",
    "    all_tweets = pd.concat([all_tweets, new_tweets], axis=0)\n",
    "    \n",
    "    \n",
    "    #Set max_id for next iteration --------------------#\n",
    "    max_id = new_tweets.id.values[-1]\n",
    "    \n",
    "    count += len(tweets_copy)\n",
    "    \n",
    "    print(f\"Current date and time: {str(datetime.now())}\")\n",
    "    print(f\"Tweets collection count: {count :,}\")\n",
    "    print(f\"Latest Tweet timestamp: {new_tweets.timestamp.values[-1]}\")\n",
    "        \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    if DEBUG:\n",
    "        break\n",
    "    #break\n",
    "    \n",
    "#-----------------------------------------------------------#\n",
    "print(f\"Total tweets collected: {len(all_tweets) :,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2020-11-01T23:59:57.000000000')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.timestamp.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Save the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1. Merge past and present data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new tweets: 23,850; all tweets: 645,254\n"
     ]
    }
   ],
   "source": [
    "if toConcate:\n",
    "    tweets_all_df = pd.concat([all_tweets, tweets_old_df], axis=0)\n",
    "    tweets_all_df.reset_index(inplace=True)\n",
    "else:\n",
    "    tweets_all_df = all_tweets\n",
    "    \n",
    "print(f\"new tweets: {all_tweets.shape[0] :,}; all tweets: {tweets_all_df.shape[0] :,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2. Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all tweets: (645253, 20)\n"
     ]
    }
   ],
   "source": [
    "tweets_all_df.drop_duplicates(subset = [\"id\"], inplace=True)\n",
    "tweets_all_df.reset_index(inplace=True)\n",
    "tweets_all_df.drop(columns=['index', 'level_0'], inplace=True, errors='ignore')\n",
    "\n",
    "print(f\"all tweets: {tweets_all_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>has_media_type</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>source</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1323052187539353600</td>\n",
       "      <td>Julie Frein</td>\n",
       "      <td>Headingley, Leeds, UK</td>\n",
       "      <td>BA(Hons) Art Vis Comm. Expat American living in UK, Divorced, walking a positive path. PLEASE, no DMS if only wanting a 'date'. #Resistance #lovepeople</td>\n",
       "      <td>2009-02-19 02:14:14</td>\n",
       "      <td>1222</td>\n",
       "      <td>1282</td>\n",
       "      <td>17866</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-11-01 23:59:57</td>\n",
       "      <td>@realDonaldTrump Dumpy Donnie is the candidate of rioters, looters, arsonists, gun-toting Billy-Bubbas, terrorists, lobbyists and special interests. Biden is the candidate of farmers, factory workers, police officers, and hard-working, law-abiding patriots of every race, religion and creed #BIDEN</td>\n",
       "      <td>False</td>\n",
       "      <td>[BIDEN]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.323031e+18</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id    user_name          user_location  \\\n",
       "0  1323052187539353600  Julie Frein  Headingley, Leeds, UK   \n",
       "\n",
       "                                                                                                                                          user_description  \\\n",
       "0  BA(Hons) Art Vis Comm. Expat American living in UK, Divorced, walking a positive path. PLEASE, no DMS if only wanting a 'date'. #Resistance #lovepeople   \n",
       "\n",
       "          user_created  user_followers  user_friends  user_favourites  \\\n",
       "0  2009-02-19 02:14:14            1222          1282            17866   \n",
       "\n",
       "   user_verified coordinates            timestamp  \\\n",
       "0          False        None  2020-11-01 23:59:57   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                        text  \\\n",
       "0  @realDonaldTrump Dumpy Donnie is the candidate of rioters, looters, arsonists, gun-toting Billy-Bubbas, terrorists, lobbyists and special interests. Biden is the candidate of farmers, factory workers, police officers, and hard-working, law-abiding patriots of every race, religion and creed #BIDEN   \n",
       "\n",
       "   truncated hashtags  retweet_count  favorite_count has_media_type  \\\n",
       "0      False  [BIDEN]              0               0           None   \n",
       "\n",
       "   in_reply_to_status_id           source  is_retweet  \n",
       "0           1.323031e+18  Twitter Web App       False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_all_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3. Export the updated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645,253 tweets, from 2020-10-01 22:14:28 to 2020-11-01 23:59:57, saved at 2020-11-02 09:42:05.708817\n"
     ]
    }
   ],
   "source": [
    "tweets_all_df.to_csv(fname, index=False)\n",
    "start = tweets_all_df.timestamp.values[-1]\n",
    "end   = tweets_all_df.timestamp.values[0]\n",
    "\n",
    "print(f\"{len(tweets_all_df) :,} tweets, from {start} to {end}, saved at {str(datetime.now())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
